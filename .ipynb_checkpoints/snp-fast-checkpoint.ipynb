{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca97a55-1ca3-48b1-ab60-92fd33752709",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ОБЩИЙ ДЛЯ ВСЕХ РЕШЕНИЙ КОД\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872289e9-b5cf-4c77-9ef4-647a949adb17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# НАСТРОЙКА JUPYTER LAB И ПОДКЛЮЧЕНИЕ БИБЛИОТЕК\n",
    "\n",
    "# Импортировать библиотеки: numpy, pandas pandasql для работы с датасетами\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "\n",
    "# Импортировать библиотеку datetime для работы с датой, временем\n",
    "import datetime as dt\n",
    "\n",
    "# Импортировать библиотеки pathlib и csv для работы с файлами и импорта csv\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# Импортировать библиотеки hashlib для работы с криптофункциями в том числе с 'md5'\n",
    "import hashlib as hs\n",
    "\n",
    "# Настройка среды Jupyter Lab\n",
    "pd.options.display.max_rows = 400\n",
    "\n",
    "# БЛОК ИМПОРТА ИСХОДНЫХ ВЕСОВЫХ ДАННЫХ\n",
    "\n",
    "    # загружаем исходные данные из файла с записями с весовыми показателями и номерами вагонов;\n",
    "    # чистим загруженные данные;\n",
    "    # генерируем и добавляем производные данные о массе;\n",
    "    # на выходе получаем таблицу 'scales'\n",
    "# Подготовить путь к исходным CSV файлам\n",
    "dir_path = Path.cwd()\n",
    "\n",
    "# Загрузить данные из файла *scales*, файл содержит сырые данные по измеренным показателям массы\n",
    "# номер состава, номер вагона, дата/время, и ряд друхих\n",
    "\n",
    "\n",
    "# Подготовить переменную с именем импортируемого CSV файла с массами цистерн\n",
    "file_name_scales = '01__snp-scales.csv'\n",
    "path_file_scales = Path(dir_path,'res', 'data', file_name_scales)\n",
    "\n",
    "# Загрузить таблицу с данными взвешивания\n",
    "with open(path_file_scales, \"r\", encoding='utf-8') as csv_file_scales:\n",
    "    scales = pd.read_csv(csv_file_scales,\n",
    "                         delimiter=';',\n",
    "                         header=0,\n",
    "                         names=  ['trnum', 'num', 'bdatetime', 'invnum', 'tcalibr', 'tare', 'brutto', 'netto', 'velocity'] )\n",
    "\n",
    "# Добавить новый индексный столбец 'id_scales'\n",
    "scales['id_scales'] = np.arange(2, len(scales['invnum'])+2, 1)\n",
    "\n",
    "# Зафиксировать количество записей полученных из CSV файла\n",
    "len_scales = len(scales)\n",
    "\n",
    "# Привести даты к типу datetime\n",
    "scales['bdatetime'] = pd.to_datetime(scales['bdatetime'], dayfirst=True, format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# ЧИСТИМ ДАННЫЕ\n",
    "# Удалить не нужные столбцы: 'tcalibr', 'netto1', 'velocity'\n",
    "scales.drop(['tcalibr', 'velocity'], axis=1, inplace=True)\n",
    "\n",
    "# Удалить строки у которых значение столбца invnum = NaN\n",
    "scales.dropna(subset=['invnum'], inplace=True)\n",
    "\n",
    "# Заменить тип столбца 'invnum' на int64\n",
    "scales['invnum'] = scales['invnum'].astype('int64')\n",
    "\n",
    "# ГЕНЕРИРОВАТЬ И ДОБАВИТЬ ПРОИЗВОДНЫЕ ДАННЫЕ\n",
    "# Добавить новый столбец 'deltaweight' содержащий разницу массы на въезде и на выезде\n",
    "scales['deltaweight'] = scales['brutto'] - scales['tare']\n",
    "\n",
    "# Задать новый порядок столбцов и проиндексировать\n",
    "scales=scales.reindex(columns=['id_scales', 'trnum', 'invnum', 'num', 'bdatetime', 'tare', 'brutto', 'netto', 'deltaweight'])\n",
    "\n",
    "# РАЗБИТЬ ПОЛУЧЕННЫЕ ДАННЫЕ ДВЕ ОСНОВНЫЕ РАБОЧИЕ ТАБЛИЦЫ\n",
    "\n",
    "    # выделить набор scales_in - записи с составами ВЪЕХАВШИМИ на базу;\n",
    "    # выделить набор scales_out - записи с составами ВЫЕХАВШИМИ с базы;\n",
    "    # разделение провести по значению '0' в поле 'tare'\n",
    "    # на выходе получаем таблицы 'scales_in' и 'scales_out'\n",
    "\n",
    "# ВЫделить в отдельную таблицу 'scales_in' записи с транзакцией заехавших составов, по условию 'tare' = 0\n",
    "scales_in = scales[ scales['tare'] == 0 ]\n",
    "# ВЫделить в отдельную таблицу 'scales_out' записи с транзакцией выехавших составов, по условию 'tare' != 0\n",
    "scales_out = scales[ scales['tare'] != 0 ]\n",
    "\n",
    "# Задать индексацию по 'id_scales'\n",
    "#scales_in = scales_in.set_index(keys = ['id_scales'], drop=False)\n",
    "#scales_out = scales_out.set_index(keys = ['id_scales'], drop=False)\n",
    "\n",
    "# БЛОК ИМПОРТА ИСХОДНЫХ ДАННЫХ ПО ОТБРАКОВКЕ\n",
    "\n",
    "    # загружаем исходные данные из файла с записями о забракованных вагонов;\n",
    "    # генерируем и добавляем поле 'id_marriag', которое позволит сопоставлять записи результатов работы программы с исходными 'грязными' данными до обработки\n",
    "    # чистим загруженные данные;\n",
    "    # на выходе получаем таблицу 'marriag'\n",
    "\n",
    "# Загрузить данные из файла *marriag*, файл содержит сырые данные по отбракованным вагонам\n",
    "# В итоге сосздается dataset 'marriag'\n",
    "\n",
    "# Подготовить переменную с именем импортируемого CSV файла с дефектными цистернами\n",
    "file_name_marriag = '02__snp-marriag.csv'\n",
    "path_file_marriag = Path(dir_path,'res', 'data', file_name_marriag)\n",
    "\n",
    "# Загрузить таблицу с данными отбраковки\n",
    "with open(path_file_marriag, \"r\", encoding='utf-8') as csv_file_marriag:\n",
    "    marriag = pd.read_csv(csv_file_marriag,\n",
    "                          delimiter=';',\n",
    "                          header=0,\n",
    "                          names=  ['n', 'invnum', 'tcalibr', 'mass', 'nact', 'bdatetime', 'reason', 'contractor'])\n",
    "\n",
    "# Добавить индексный столбец ID с индексом\n",
    "marriag['id_marriag'] = np.arange(2, len(marriag['invnum'])+2, 1)\n",
    "\n",
    "# Удалить не нужные столбцы\n",
    "marriag.drop(['tcalibr', 'mass'], axis=1, inplace=True)\n",
    "\n",
    "# Привести даты к типу datetime\n",
    "marriag['bdatetime'] = pd.to_datetime(marriag['bdatetime'], dayfirst=True, format='%d.%m.%Y')\n",
    "\n",
    "# Задать новый порядок столбцов и проиндексировать\n",
    "marriag = marriag.reindex(columns=['invnum', 'id_marriag',  'bdatetime', 'n', 'nact', 'reason', 'contractor'])\n",
    "\n",
    "# Задать индексацию по 'id_marriag'\n",
    "marriag = marriag.set_index(keys = ['id_marriag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7fed7-4468-4da9-b0f4-3ad72bc81357",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ВЕТКА 1  \n",
    "---\n",
    "РЕШЕНИЕ ЗАДАЧИ ЧЕРЕЗ ЯВНО СУЩЕСТВУЮЩИЕ ПРИЗНАКИ. НЕ ВВОДИТСЯ И НЕ ИСПОЛЬЗУЕТСЯ ПОНЯТИЕ HASH ЗНАЧЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce9b5207-d8c3-4857-9273-0b7f1300ee82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# БЛОК СОЕДИНЕНИЯ ЗАПИСЕЙ 'scales_in' И 'scales_out'\n",
    "\n",
    "# В данном блоке производится объединение записей таблиц 'scales_in' и 'scales_out' для получения 'правильных' записей о транзакции\n",
    "# состава и всех входящих в него вагонов которые въехали на базу для налива и выехали после. Соединение производится по правилу LEFT JOIN\n",
    "# с выполнением тройного условия. Так как 'pandas' не умеет выполнять оьбъединенеия по нечеткому соответствию (а именно таким получается\n",
    "# третье условие), то для соединения была задействована дополнительная библиотека 'pandassql' которая работает поверх 'pandas' и перегоняет\n",
    "# (динамичесуки) данные в SQL базу данных SQLite, и позволяет выполнить преобразование с помощью команд SQL, а после обратно сохранить в\n",
    "# объекты 'pandas' - DataFrames.\n",
    "# Условия соединенеия подразумевают совпадения следующих полей обеих DataFrames:\n",
    "\n",
    "    # 'invnum';\n",
    "    # 'num';\n",
    "    # нечеткое совпадение временного поля 'bdatetime' (по принципу оконной функции);\n",
    "    # на выходе получаем таблицу 'scales_join';\n",
    "\n",
    "# Подготовить SQL запрос для левого соединения таблиц 'scales_in' и 'scales_out' с помощью функционала библиотеки 'pandasql'\n",
    "\n",
    "join_query_scales = '''\n",
    "    SELECT\n",
    "        l.id_scales      as id_scales\n",
    "        ,r.trnum         as trnum_in\n",
    "        ,l.trnum         as trnum_out\n",
    "        ,r.invnum        as invnum_in\n",
    "        ,l.invnum        as invnum_out\n",
    "        ,r.num           as num_in\n",
    "        ,l.num           as num_out\n",
    "        ,r.bdatetime     as date_in\n",
    "        ,l.bdatetime     as date_out\n",
    "        ,r.brutto        as tare_in\n",
    "        ,l.tare          as tare_out\n",
    "        ,l.brutto        as brutto\n",
    "        ,l.netto         as netto\n",
    "        ,l.deltaweight   as deltaweight\n",
    "    FROM scales_in as r LEFT JOIN scales_out as l\n",
    "         ON (r.invnum = l.invnum)\n",
    "            AND (r.num = l.num)\n",
    "            AND (cast(strftime('%s',r.bdatetime) as interger)\n",
    "                BETWEEN cast(strftime('%s',l.bdatetime, '-37 hours') as interger) AND cast(strftime('%s',l.bdatetime) as interger) )\n",
    "'''\n",
    "\n",
    "# Выполнить ранее подготовленный запрос средствами библиотеки 'pandasql', получить результирующую таблицу\n",
    "scales_join = ps.sqldf(join_query_scales, locals())\n",
    "\n",
    "# Привести даты к типу datetime\n",
    "scales_join['date_in'] = pd.to_datetime(scales_join['date_in'])\n",
    "scales_join['date_out'] = pd.to_datetime(scales_join['date_out'])\n",
    "\n",
    "# Вставить столбец 'deltatetime' с данными разницы времени (дени - часа - минуты - секунды) между событием 'въехал' и событием 'выехал'\n",
    "scales_join.insert(9, 'deltatetime', scales_join['date_out']-scales_join['date_in'])\n",
    "\n",
    "# Нормировать разницу к формату 00,00 (часы и доли часа)\n",
    "scales_join['deltatetime'] = (scales_join['deltatetime']/pd.Timedelta('1 hour')).round(2)\n",
    "\n",
    "# Преобразовать 'deltatetime' к string и заменить '.' на ',' т.к. импортирует с '.' асурд\n",
    "scales_join['deltatetime'] = scales_join['deltatetime'].astype(str).str.replace('.', ',', regex=False)\n",
    "scales_join['deltatetime'] = scales_join['deltatetime'].astype(str).str.replace('nan', '', regex=False)\n",
    "\n",
    "# Заменить NaN в столбцах 'trnum_out', 'invnum_out', 'num_out', 'brutto', 'netto', 'deltaweigth' на 0\n",
    "scales_join[[ 'id_scales'\n",
    "             ,'trnum_out'\n",
    "             ,'invnum_out'\n",
    "             ,'num_out'\n",
    "             ,'deltatetime'\n",
    "             ,'tare_out'\n",
    "             ,'brutto'\n",
    "             ,'netto'\n",
    "             ,'deltaweight']] = scales_join[['id_scales', 'trnum_out', 'invnum_out', 'num_out' ,'deltatetime', 'tare_out', 'brutto', 'netto', 'deltaweight']].fillna(0)\n",
    "\n",
    "# Заменить тип в столбцах 'trnum_out', 'invnum_out', 'num_out', 'brutto', 'netto', 'deltaweigth' на int64\n",
    "scales_join[[ 'id_scales'\n",
    "             ,'trnum_out'\n",
    "             ,'invnum_out'\n",
    "             ,'num_out'\n",
    "             ,'tare_out'\n",
    "             ,'brutto'\n",
    "             ,'netto'\n",
    "             ,'deltaweight']] = scales_join[['id_scales', 'trnum_out', 'invnum_out', 'num_out', 'tare_out','brutto', 'netto', 'deltaweight']].astype('int64')\n",
    "\n",
    "# БЛОК СОХРАНЕНИЯ ПРОМЕЖУТОЧНОГО ФАЙЛА CSV С ДАННЫМИ ТАБЛИЦЫ 'scales_join'\n",
    "    # на выходе получаем CSV файл\n",
    "\n",
    "# Подготовить переменную с именем экспортируемого CSV файла\n",
    "file_name_scales_join_csv = '03__result-scales-correct-branch1.csv'\n",
    "path_file_scales_join_csv = Path(dir_path,'res', 'data', file_name_scales_join_csv)\n",
    "\n",
    "file_name_scales_join_excel = '03__result-scales-correct-branch1.xlsx'\n",
    "path_file_scales_join_excel = Path(dir_path,'res', 'data', file_name_scales_join_excel)\n",
    "\n",
    "# Записать данные в таблицу\n",
    "scales_join.to_csv(str(path_file_scales_join_csv), index=False, sep=';', encoding='utf-8')\n",
    "scales_join.to_excel(str(path_file_scales_join_excel), index=False)\n",
    "\n",
    "# БЛОК СОЕДИНЕНИЯ ЗАПИСЕЙ 'scales_join' И 'marriag' ДЛЯ ПОЛУЧЕНИЯ ТАБЛИЦЫ ЯВЛЯЮЩЕЙСЯ РЕШЕНИЕМ ЗАДАЧИ\n",
    "\n",
    "# В данном блоке производится объединение записей таблиц scales_join и 'marriag' для получения итоговоЙ ТАБЛИЦЫ, которая является решением задачи.\n",
    "# Позже на ее основе будет получен итоговый выходной файл правильных' записей о транзакции состава и всех входящих в него вагонов которые въехалина\n",
    "# базу для налива и выехали после. Соединение производится по правилу LEFT JOIN с выполнением двойного условия. Так как 'pandas' не умеет выполнять\n",
    "# объединенеия по нечеткому соответствию (а именно таким получается второе условие), то для соединения была задействована дополнительная библиотека\n",
    "# 'pandassql' которая работает поверх 'pandas' и перегоняет (динамически) данные в SQL базу данных SQLite, далее позволяет выполнить преобразование\n",
    "# с помощью команд SQL, а после обратно сохранить в объекты 'pandas' - DataFrames. Условия соединенеия подразумевают совпадения следующих полей обеих таблиц:\n",
    "\n",
    "    # 'invnum_out' и 'invnum';\n",
    "    # нечеткое совпадение временного поля 'bdatetime' (по принципу оконной функции);\n",
    "    # на выходе получаем таблицу 'join_hash_table';\n",
    "\n",
    "\n",
    "# Подготовить SQL запрос для левого соединения таблиц 'scales_join' и 'marriag'\n",
    "\n",
    "join_query_result_table = '''\n",
    "    SELECT\n",
    "        ROW_NUMBER() OVER(ORDER BY l.id_scales) + 1 as id_result\n",
    "        ,l.id_scales   as id_scales\n",
    "        ,r.id_marriag  as id_marriag\n",
    "        ,l.trnum_in    as trnum_in\n",
    "        ,l.trnum_out   as trnum_out\n",
    "        ,l.invnum_in   as invnum_in\n",
    "        ,l.invnum_out  as invnum_out\n",
    "        ,l.num_in      as num_in\n",
    "        ,l.num_out     as num_out\n",
    "        ,l.date_in     as date_in\n",
    "        ,l.date_out    as date_out\n",
    "        ,r.bdatetime   as date_marriag\n",
    "        ,l.deltatetime as deltatetime\n",
    "        ,l.tare_in     as tare_in\n",
    "        ,l.tare_out    as tare_out\n",
    "        ,l.brutto      as brutto\n",
    "        ,l.netto       as netto\n",
    "        ,l.deltaweight as deltaweight\n",
    "        ,r.nact        as nact\n",
    "        ,r.reason      as reason\n",
    "    FROM scales_join as l LEFT JOIN marriag as r\n",
    "         ON (l.invnum_out = r.invnum)\n",
    "            AND (cast(strftime('%s',r.bdatetime) as interger)\n",
    "                BETWEEN cast(strftime('%s',l.date_out, '-30 hours') as interger) AND cast(strftime('%s',l.date_out) as interger) )        \n",
    "'''\n",
    "\n",
    "# Выполнить ранее подготовленный запрос средствами библиотеки 'pandasql', получить результирующую таблицу\n",
    "join_table = ps.sqldf(join_query_result_table, locals())\n",
    "\n",
    "# Привести даты к типу datetime\n",
    "join_table['date_in'] = pd.to_datetime(join_table['date_in'])\n",
    "join_table['date_out'] = pd.to_datetime(join_table['date_out'])\n",
    "join_table['date_marriag'] = pd.to_datetime(join_table['date_marriag'])\n",
    "\n",
    "# Заменить NaN в столбце 'id_marriag' на 0\n",
    "join_table['id_marriag'] = join_table['id_marriag'].fillna(0)\n",
    "\n",
    "# Заменить тип столбца 'id_marriag' на int64\n",
    "join_table['id_marriag'] = join_table['id_marriag'].astype('int64')\n",
    "\n",
    "# Заменить None в столбце 'nact' на 0\n",
    "join_table['nact'] = join_table['nact'].fillna(0)\n",
    "\n",
    "# Заменить тип столбца 'nact' на int64\n",
    "join_table['nact'] = join_table['nact'].astype('int64')\n",
    "\n",
    "\n",
    "# БЛОК СОХРАНЕНИЯ РЕШЕНИЯ ЗАДАЧИ ПО МЕТОДУ 'ВЕТКА 1' В CSV ФАЙЛ\n",
    "    # на выходе получаем CSV файл сгенерированный в соответствии с логикой 'ВЕТКА 1'\n",
    "\n",
    "# Подготовить переменную с именем результирующего CSV файла\n",
    "file_name_join = '05__result-table-branch1.csv'\n",
    "path_file_join = Path(dir_path,'res', 'data', file_name_join)\n",
    "\n",
    "file_name_join_excel = '05__result-table-branch1.xlsx'\n",
    "path_file_join_excel = Path(dir_path,'res', 'data', file_name_join_excel)\n",
    "\n",
    "# Записать в данные в файл\n",
    "join_table.to_csv(str(path_file_join), index=False, sep=';', encoding='utf-8')\n",
    "join_table.to_excel(str(path_file_join_excel), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b387fd-416a-48ab-b0b9-667e404ac5f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ВЕТКА 2  \n",
    "---\n",
    "РЕШЕНИЕ ЗАДАЧИ ЧЕРЕЗ НЕ ЯВНО СУЩЕСТВУЮЩИЕ ПРИЗНАКИ. ДЛЯ РЕШЕНИЯ ВВОДИТСЯ И ИСПОЛЬЗУЕТСЯ ПОНЯТИЕ HASH ЗНАЧЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e331fd-b8da-43b4-9b50-30a79a52ff98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ГРУППИРОВКА ДАННЫХ В DATAFRAMES scales_in И scales_out\n",
    "\n",
    "# В данном блоке производится группировка записей таблиц 'scales_in' и 'scales_out' для получения сгруппированных по значению номера состава\n",
    "# 'trnum' записей. Это нужно для достижения нескольких целей:\n",
    "\n",
    "    # определения количества составов отдельно в таблицах въехавших и выехавших составов;\n",
    "    # подготовка данных в обеих таблицах к такой форме хранения которая позволит эффективно вычислить hash значения;\n",
    "    # вычисления комплексных характеристик каждого состава в обеих таблицах - hash значения;\n",
    "\n",
    "# Выработка требований к hash значению - нам потребуется определить такую группу характеристик которая атомарно представляет уникальную\n",
    "# характеристику состава, причем должна имется 100% возможность получить такую группу как в таблице въехавших составах так и в таблице\n",
    "# выехавших составов. Это требование должно не укоснительно выполняться, так как в дальнейшем полученный слепок состава - hash значение\n",
    "# должно стать идентификатором по которому будет искаться совпадение и далее проводиться объединение данных по идентичным составам из обеих таблиц.\n",
    "# В качестве такого группового признака который имперически определен как абсолютно не повторяемый ни при каких условиях - последовательность\n",
    "# значений номеров состава а также (одновременно) позиционный номер вагона в составе, т.е. математическая последовательность значений номеров вагонов.\n",
    "# Для упрощения кода, фактор порядкового номера был заменен на не явный, а именно перед вычислением hash значения номера вагонов превращены в текстовые\n",
    "# значения и произведена конкатенация строго в той последовательности в которой вагоны шли в составе. В итоге входным параметром функции-генератора\n",
    "# hash значения стала тестовая строка состаящая из непрерывно сцепленных значений текстовых эквивалентов номеров вагонов.\n",
    "# В качестве функции-генератора hash значения применена - MD5\n",
    "\n",
    "\n",
    "# Вывести первые 3 записи (до группировки) комплементарных групп которе далее должны сгруппироваться а далее объединиться\n",
    "# это требуется для визуального контроля\n",
    "scales_in[ scales_in['trnum'] == 683482 ].sort_values(by='num').head(3)\n",
    "\n",
    "# Произвести группировку по номеру состава ('trnum')\n",
    "gr_scales_in = scales_in.groupby('trnum')\n",
    "gr_scales_out = scales_out.groupby('trnum')\n",
    "\n",
    "# БЛОК ГЕНЕРАЦИИ HASH ЗНАЧЕНИЙ\n",
    "\n",
    "# Функция вычисляет hash значение группы\n",
    "def HashRow(_df):\n",
    "    \n",
    "    hash_total_str = ''\n",
    "    \n",
    "    df = _df.sort_values(by='num', ascending=True)\n",
    "    # Перебрать все строки текущей группы, получить текстовый объект hash всех номеров вагонов группы\n",
    "    for data in df.itertuples():\n",
    "        hash_total_str += str(data[3])\n",
    "    \n",
    "    hash_object = hs.md5(hash_total_str.encode('utf-8'))\n",
    "    #return int(hash_object.hexdigest(), 16)\n",
    "    return hash_object.hexdigest()\n",
    "\n",
    "# Функция выпоняет перебор всех групп и вызывает функцию вычисления hash значения группы\n",
    "def HashGroup(_df):\n",
    "    \n",
    "    hash_dict = {} # Словарь хранящий пару 'Номер состава: hash состава'\n",
    "    cycle = 0\n",
    "    \n",
    "    # Перебраить все группы сгруппированого DataFrame\n",
    "    for name, group in _df:\n",
    "        if cycle>0:\n",
    "            break\n",
    "        hash_dict[name] = HashRow(group) # Для каждой группы вызвать hash функцию\n",
    "    return hash_dict\n",
    "\n",
    "# Сгенерировать словари с hash значениями групп составовs\n",
    "hash_dict_in  = HashGroup(gr_scales_in)\n",
    "hash_dict_out = HashGroup(gr_scales_out)\n",
    "\n",
    "# Преобразовать dictonari в DataFrame\n",
    "hash_df_in = pd.DataFrame(hash_dict_in.items(), columns=['trnum', 'hash_group'])\n",
    "hash_df_out = pd.DataFrame(hash_dict_out.items(), columns=['trnum', 'hash_group'])\n",
    "\n",
    "# БЛОК СОЕДИНЕНИЯ ТАБЛИЦ 'scales_in','scales_out' С СООТВЕТСТВУЮЩИМИ ТАБЛИЦАМИ HASH ЗНАЧЕНИЙ\n",
    "\n",
    "# Выполнить левое соединение таблиц 'scales_hash_in', 'scales_hash_out' с соответствующими таблицами hash значений\n",
    "scales_hash_in = scales_in.merge(hash_df_in, on='trnum', how='left')\n",
    "scales_hash_out = scales_out.merge(hash_df_out, on='trnum', how='left')\n",
    "\n",
    "# БЛОК СОЕДИНЕНИЯ ЗАПИСЕЙ 'scales_hash_in' И 'scales_hash_out' ДЛЯ ПОЛУЧЕНИЯ ТАБЛИЦЫ 'scales_join_hash'\n",
    "# КОТОРАЯ ХРАНИТ ОБЪЕДИНЕНЫЕ ЗАПИСИ ВЪЕХАВШИХ И ВЫЕХАВШИХ СОСТАВОВ.\n",
    "\n",
    "# АНАЛОГИЧНАЯ ТАБЛИЦА ПОЛУЧЕНА РАНЕЕ В ВЕТКЕ 1 ПО ОТЛИЧНОМУ ОТ ВЕТКЕ 2 АЛГОРИТМУ, А ИМЕННО БЕЗ ИСПОЛЬЗОВАНИЯ HASH ЗНАЧЕНИЙ\n",
    "\n",
    "# В данном блоке производится соединение записей таблиц 'scales_hash_in' и 'scales_hash_out'. Позже на основе результирующей\n",
    "# таблицы 'scales_join_hash' будет записан результирующий выходной файл CSV файл, являющийся решением задачи.\n",
    "# Соединение производится по правилу LEFT JOIN с выполнением тройного условия. В данном случае у нас все три условия четкие,\n",
    "# поэтому можно произвести объединение средствами библиотеки 'pandas', но из за экономии времени, единообразности технических\n",
    "# решений ранее уже примененных в данной программе, а также гибкости компоновки сстолбцов итоговой таблицы, соединение будет\n",
    "# производится средствами библиотеки 'pandassql', которая работает поверх 'pandas' и перегоняет (динамически) данные в SQL базу\n",
    "# данных SQLite, далее позволяет выполнить преобразование с помощью команд SQL, а после обратно сохранить в объекты 'pandas' - DataFrames.\n",
    "# Условия соединенеия подразумевают совпадения следующих полей обеих таблиц:\n",
    "\n",
    "    # 'invnum_out' и 'invnum';\n",
    "    # 'num' обеих таблиц;\n",
    "    # 'hash_group' обеих таблиц;\n",
    "    # на выходе получаем таблицу 'scales_join_hash';\n",
    "\n",
    "    # Преобразуем тип 'hash_group' в string, потому что pandassql не умеет конвертировать int large в целочисленные типы SQLite\n",
    "\n",
    "# Данное действие требуется только для варианта программы где 'hash' значение конвертировалось в int larg, если работа ведется \n",
    "# с текстовыми 'hash' значениями то оно не нужно, поэтому эти строки кода могут быть закоментированы\n",
    "\n",
    "#scales_hash_in['hash_group'] = scales_hash_in['hash_group'].astype(str)\n",
    "#scales_hash_out['hash_group'] = scales_hash_out['hash_group'].astype(str)\n",
    "\n",
    "# Подготовить SQL запрос для левого соединения таблиц 'scales_hash_in' и 'scales_hash_out'\n",
    "join_query_scales_hash = '''\n",
    "    SELECT\n",
    "        l.id_scales     as id_scales\n",
    "        ,l.trnum         as trnum_in\n",
    "        ,r.trnum         as trnum_out\n",
    "        ,l.invnum        as invnum_in\n",
    "        ,r.invnum        as invnum_out\n",
    "        ,l.num           as num_in\n",
    "        ,l.num           as num_out\n",
    "        ,l.bdatetime     as date_in\n",
    "        ,r.bdatetime     as date_out\n",
    "        ,l.brutto        as tare_in\n",
    "        ,r.tare          as tare_out\n",
    "        ,r.brutto        as brutto\n",
    "        ,r.netto         as netto\n",
    "        ,r.deltaweight   as deltaweight\n",
    "        ,l.hash_group    as hash_group\n",
    "    FROM scales_hash_in as l LEFT JOIN scales_hash_out as r\n",
    "         ON     (l.invnum     = r.invnum)\n",
    "            AND (l.num        = r.num)\n",
    "            AND (l.hash_group = r.hash_group)\n",
    "'''\n",
    "\n",
    "# Выполнить ранее подготовленный запрос средствами библиотеки 'pandasql', получить результирующую таблицу\n",
    "scales_join_hash = ps.sqldf(join_query_scales_hash, locals())\n",
    "\n",
    "# Привести даты к типу datetime\n",
    "scales_join_hash['date_in']  = pd.to_datetime(scales_join_hash['date_in'])\n",
    "scales_join_hash['date_out'] = pd.to_datetime(scales_join_hash['date_out'])\n",
    "\n",
    "# Вставить столбец 'deltatetime' с данными разницы времени (дени - часа - минуты - секунды) между событием 'въехал' и событием 'выехал'\n",
    "scales_join_hash.insert(9, 'deltatetime', scales_join_hash['date_out']-scales_join_hash['date_in'])\n",
    "\n",
    "# Нормировать разницу к формату 00,00 (часы и доли часа)\n",
    "scales_join_hash['deltatetime'] = (scales_join_hash['deltatetime']/pd.Timedelta('1 hour')).round(2)\n",
    "\n",
    "# Преобразовать 'deltatetime' к string и заменить '.' на ',' т.к. импортирует с '.' для дальнейшего использования совместно с Excel\n",
    "scales_join_hash['deltatetime'] = scales_join_hash['deltatetime'].astype(str).str.replace('.', ',', regex=False)\n",
    "\n",
    "# Заменить NaN в столбцах 'trnum_out', 'invnum_out', 'num_out', 'brutto', 'netto', 'deltaweigth' на 0\n",
    "scales_join_hash[['trnum_out'\n",
    "                 ,'invnum_out'\n",
    "                 ,'num_out'\n",
    "                 ,'deltatetime'\n",
    "                 ,'tare_out'\n",
    "                 ,'brutto'\n",
    "                 ,'netto'\n",
    "                 ,'deltaweight']] = scales_join_hash[['trnum_out', 'invnum_out', 'num_out' ,'deltatetime', 'tare_out', 'brutto', 'netto', 'deltaweight']].fillna(0)\n",
    "\n",
    "# Заменить тип в столбцах 'trnum_out', 'invnum_out', 'num_out', 'brutto', 'netto', 'deltaweigth' на int64\n",
    "scales_join_hash[['trnum_out'\n",
    "                 ,'invnum_out'\n",
    "                 ,'num_out'\n",
    "                 ,'tare_out'\n",
    "                 ,'brutto'\n",
    "                 ,'netto'\n",
    "                 ,'deltaweight']] = scales_join_hash[['trnum_out', 'invnum_out', 'num_out', 'tare_out','brutto', 'netto', 'deltaweight']].astype('int64')\n",
    "\n",
    "# БЛОК СОХРАНЕНИЯ ПРОМЕЖУТОЧНОГО ФАЙЛА CSV С ДАННЫМИ ТАБЛИЦЫ 'scales_join'\n",
    "    # на выходе получаем CSV файл сгенерированный в соответствии с логикой 'ВЕТКА 2'\n",
    "\n",
    "# Подготовить переменную с именем экспортируемого CSV файла \n",
    "file_name_scales_join_hash_csv = '04__result-scales-correct-branch2.csv'\n",
    "path_file_scales_join_hash_csv = Path(dir_path,'res', 'data', file_name_scales_join_hash_csv)\n",
    "\n",
    "# Записать в данные в таблицу\n",
    "scales_join_hash.to_csv(str(path_file_scales_join_hash), index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "# БЛОК СОЕДИНЕНИЯ ЗАПИСЕЙ 'scales_join_hash' И 'marriag' ДЛЯ ПОЛУЧЕНИЯ ТАБЛИЦЫ ЯВЛЯЮЩЕЙСЯ РЕШЕНИЕМ ЗАДАЧИ\n",
    "# В данном блоке производится объединение записей таблиц scales_join_hash и 'marriag' для получения итоговоЙ ТАБЛИЦЫ,\n",
    "# которая является решением задачи. Позже на ее основе будет получен итоговый выходной файл правильных' записей о транзакции\n",
    "# состава и всех входящих в него вагонов которые въехали на базу для налива и выехали после. Соединение производится по правилу\n",
    "# LEFT JOIN с выполнением двойного условия. Так как 'pandas' не умеет выполнять оьбъединенеия по нечеткому соответствию (а именно\n",
    "# таким получается второе условие), то для соединения была задействована дополнительная библиотека 'pandassql' которая работает\n",
    "# поверх 'pandas' и перегоняет (динамически) данные в SQL базу данных SQLite, далее позволяет выполнить преобразование с помощью\n",
    "# команд SQL, а после обратно сохранить в объекты 'pandas' - DataFrames. Условия соединенеия подразумевают совпадения следующих\n",
    "# полей обеих таблиц:\n",
    "\n",
    "    # 'invnum_out' и 'invnum';\n",
    "    # нечеткое совпадение временного поля 'bdatetime' (по принципу оконной функции);\n",
    "    # на выходе получаем таблицу 'join_table';\n",
    "\n",
    "# Подготовить SQL запрос для левого соединения таблиц 'scales_join_hash' и 'marriag'\n",
    "\n",
    "join_hash_query_result_table = '''\n",
    "    SELECT\n",
    "        ROW_NUMBER() OVER(ORDER BY l.id_scales) + 1 as id_result\n",
    "        ,l.id_scales   as id_scales\n",
    "        ,r.id_marriag  as id_marriag\n",
    "        ,l.trnum_in    as trnum_in\n",
    "        ,l.trnum_out   as trnum_out\n",
    "        ,l.invnum_in   as invnum_in\n",
    "        ,l.invnum_out  as invnum_out\n",
    "        ,l.num_in      as num_in\n",
    "        ,l.num_out     as num_out\n",
    "        ,l.date_in     as date_in\n",
    "        ,l.date_out    as date_out\n",
    "        ,r.bdatetime   as date_marriag\n",
    "        ,l.deltatetime as deltatetime\n",
    "        ,l.tare_in     as tare_in\n",
    "        ,l.tare_out    as tare_out\n",
    "        ,l.brutto      as brutto\n",
    "        ,l.netto       as netto\n",
    "        ,l.deltaweight as deltaweight\n",
    "        ,r.nact        as nact\n",
    "        ,r.reason      as reason\n",
    "        ,l.hash_group  as hash_group\n",
    "    FROM scales_join_hash as l LEFT JOIN marriag as r\n",
    "         ON (l.invnum_out = r.invnum)\n",
    "            AND (cast(strftime('%s',r.bdatetime) as interger)\n",
    "                BETWEEN cast(strftime('%s',l.date_out, '-30 hours') as interger) AND cast(strftime('%s',l.date_out) as interger) )        \n",
    "'''\n",
    "\n",
    "# Выполнить ранее подготовленный запрос средствами библиотеки 'pandasql', получить результирующую таблицу\n",
    "join_hash_table = ps.sqldf(join_hash_query_result_table, locals())\n",
    "\n",
    "# Привести даты к типу datetime\n",
    "join_hash_table['date_in'] = pd.to_datetime(join_hash_table['date_in'])\n",
    "join_hash_table['date_out'] = pd.to_datetime(join_hash_table['date_out'])\n",
    "join_hash_table['date_marriag'] = pd.to_datetime(join_hash_table['date_marriag'])\n",
    "\n",
    "# Заменить NaN в столбце 'id_marriag' на 0\n",
    "join_hash_table['id_marriag'] = join_hash_table['id_marriag'].fillna(0)\n",
    "\n",
    "# Заменить тип столбца 'id_marriag' на int64\n",
    "join_hash_table['id_marriag'] = join_hash_table['id_marriag'].astype('int64')\n",
    "\n",
    "# Заменить None в столбце 'nact' на 0\n",
    "join_hash_table['nact'] = join_hash_table['nact'].fillna(0)\n",
    "\n",
    "# Заменить тип столбца 'nact' на int64\n",
    "join_hash_table['nact'] = join_hash_table['nact'].astype('int64')\n",
    "\n",
    "\n",
    "# БЛОК СОХРАНЕНИЯ РЕШЕНИЯ ЗАДАЧИ ПО МЕТОДУ 'ВЕТКА 2' В CSV ФАЙЛ\n",
    "\n",
    "# Подготовить переменную с именем результирующего CSV файла\n",
    "file_name_join_hash_table = '06__result-table-branch2.csv'\n",
    "path_file_join_hash_table = Path(dir_path,'res', 'data', file_name_join_hash_table)\n",
    "\n",
    "# Записать в данные в файл\n",
    "join_hash_table.to_csv(str(path_file_join_hash_table), index=False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9996f42-e7cb-486c-a65f-f84a9c57cca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trnum</th>\n",
       "      <th>hash_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761304</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>761385</td>\n",
       "      <td>d35ed09492358eebca63cd5b274108b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>761426</td>\n",
       "      <td>e37b33865e92228d247b74e867ffd5b9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trnum                        hash_group\n",
       "0  761304  754875f74fbd809411651574e4ddeb73\n",
       "1  761385  d35ed09492358eebca63cd5b274108b0\n",
       "2  761426  e37b33865e92228d247b74e867ffd5b9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести первые записи таблицы 'hash_df_in' для визуального контроля\n",
    "hash_df_in.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe849b8b-69d1-48e0-83e7-2c913a9669d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trnum</th>\n",
       "      <th>hash_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761345</td>\n",
       "      <td>2eaaa69c379869720e5fad57e6afa228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>761426</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>761586</td>\n",
       "      <td>2fb734e9b08d3ea1a276810389556334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trnum                        hash_group\n",
       "0  761345  2eaaa69c379869720e5fad57e6afa228\n",
       "1  761426  754875f74fbd809411651574e4ddeb73\n",
       "2  761586  2fb734e9b08d3ea1a276810389556334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести первые записи таблицы 'hash_df_out' для визуального контроля\n",
    "hash_df_out.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3466b846-46e3-4172-8325-91d0259a9168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aac5aa24-3832-4d72-9157-547d5735e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_scales</th>\n",
       "      <th>trnum</th>\n",
       "      <th>invnum</th>\n",
       "      <th>num</th>\n",
       "      <th>bdatetime</th>\n",
       "      <th>tare</th>\n",
       "      <th>brutto</th>\n",
       "      <th>netto</th>\n",
       "      <th>deltaweight</th>\n",
       "      <th>hash_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>761304</td>\n",
       "      <td>73915704</td>\n",
       "      <td>41</td>\n",
       "      <td>2023-01-01 01:41:20</td>\n",
       "      <td>0</td>\n",
       "      <td>27100</td>\n",
       "      <td>0</td>\n",
       "      <td>27100</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>761304</td>\n",
       "      <td>50919992</td>\n",
       "      <td>40</td>\n",
       "      <td>2023-01-01 01:41:36</td>\n",
       "      <td>0</td>\n",
       "      <td>26350</td>\n",
       "      <td>0</td>\n",
       "      <td>26350</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>761304</td>\n",
       "      <td>50787738</td>\n",
       "      <td>39</td>\n",
       "      <td>2023-01-01 01:41:57</td>\n",
       "      <td>0</td>\n",
       "      <td>27550</td>\n",
       "      <td>0</td>\n",
       "      <td>27550</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_scales   trnum    invnum  num           bdatetime  tare  brutto  netto  \\\n",
       "0          2  761304  73915704   41 2023-01-01 01:41:20     0   27100      0   \n",
       "1          3  761304  50919992   40 2023-01-01 01:41:36     0   26350      0   \n",
       "2          4  761304  50787738   39 2023-01-01 01:41:57     0   27550      0   \n",
       "\n",
       "   deltaweight                        hash_group  \n",
       "0        27100  754875f74fbd809411651574e4ddeb73  \n",
       "1        26350  754875f74fbd809411651574e4ddeb73  \n",
       "2        27550  754875f74fbd809411651574e4ddeb73  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести первые записи для визуального контроля\n",
    "scales_hash_in.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c4531df-ee99-45cc-9454-0e1dce2f67bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6527"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести количество записей таблицы 'scales_hash_in'\n",
    "len(scales_hash_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8008f117-489e-422b-9f1c-9da8aef5122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_scales</th>\n",
       "      <th>trnum</th>\n",
       "      <th>invnum</th>\n",
       "      <th>num</th>\n",
       "      <th>bdatetime</th>\n",
       "      <th>tare</th>\n",
       "      <th>brutto</th>\n",
       "      <th>netto</th>\n",
       "      <th>deltaweight</th>\n",
       "      <th>hash_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>761345</td>\n",
       "      <td>57187395</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 03:35:54</td>\n",
       "      <td>27850</td>\n",
       "      <td>28050</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>2eaaa69c379869720e5fad57e6afa228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>761345</td>\n",
       "      <td>54240205</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 03:36:11</td>\n",
       "      <td>27100</td>\n",
       "      <td>26950</td>\n",
       "      <td>0</td>\n",
       "      <td>-150</td>\n",
       "      <td>2eaaa69c379869720e5fad57e6afa228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>761345</td>\n",
       "      <td>73090953</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-01 03:36:27</td>\n",
       "      <td>27600</td>\n",
       "      <td>88900</td>\n",
       "      <td>61300</td>\n",
       "      <td>61300</td>\n",
       "      <td>2eaaa69c379869720e5fad57e6afa228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_scales   trnum    invnum  num           bdatetime   tare  brutto  netto  \\\n",
       "0         43  761345  57187395    1 2023-01-01 03:35:54  27850   28050    200   \n",
       "1         44  761345  54240205    2 2023-01-01 03:36:11  27100   26950      0   \n",
       "2         45  761345  73090953    3 2023-01-01 03:36:27  27600   88900  61300   \n",
       "\n",
       "   deltaweight                        hash_group  \n",
       "0          200  2eaaa69c379869720e5fad57e6afa228  \n",
       "1         -150  2eaaa69c379869720e5fad57e6afa228  \n",
       "2        61300  2eaaa69c379869720e5fad57e6afa228  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести первые записи для визуального контроля\n",
    "scales_hash_out.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5a1f74f-1be9-4182-94ec-9cbdcd7e0ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6213"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести количество записей таблицы 'scales_hash_out'\n",
    "len(scales_hash_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b896a665-da2a-4da3-ad69-9d13052c2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6568 entries, 0 to 6567\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   id_scales    6568 non-null   int64         \n",
      " 1   trnum_in     6568 non-null   int64         \n",
      " 2   trnum_out    6568 non-null   int64         \n",
      " 3   invnum_in    6568 non-null   int64         \n",
      " 4   invnum_out   6568 non-null   int64         \n",
      " 5   num_in       6568 non-null   int64         \n",
      " 6   num_out      6568 non-null   int64         \n",
      " 7   date_in      6568 non-null   datetime64[ns]\n",
      " 8   date_out     6051 non-null   datetime64[ns]\n",
      " 9   deltatetime  6568 non-null   object        \n",
      " 10  tare_in      6568 non-null   int64         \n",
      " 11  tare_out     6568 non-null   int64         \n",
      " 12  brutto       6568 non-null   int64         \n",
      " 13  netto        6568 non-null   int64         \n",
      " 14  deltaweight  6568 non-null   int64         \n",
      " 15  hash_group   6568 non-null   object        \n",
      "dtypes: datetime64[ns](2), int64(12), object(2)\n",
      "memory usage: 821.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Вывести информацию о типах\n",
    "scales_join_hash.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7aa5e76f-4697-4809-ac2e-ca4027279934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6568"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести информацию о количестве записей\n",
    "len(scales_join_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b493c43c-042b-4852-8130-b910d77412a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_scales</th>\n",
       "      <th>trnum_in</th>\n",
       "      <th>trnum_out</th>\n",
       "      <th>invnum_in</th>\n",
       "      <th>invnum_out</th>\n",
       "      <th>num_in</th>\n",
       "      <th>num_out</th>\n",
       "      <th>date_in</th>\n",
       "      <th>date_out</th>\n",
       "      <th>deltatetime</th>\n",
       "      <th>tare_in</th>\n",
       "      <th>tare_out</th>\n",
       "      <th>brutto</th>\n",
       "      <th>netto</th>\n",
       "      <th>deltaweight</th>\n",
       "      <th>hash_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>761304</td>\n",
       "      <td>0</td>\n",
       "      <td>73915704</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2023-01-01 01:41:20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>nan</td>\n",
       "      <td>27100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>761304</td>\n",
       "      <td>0</td>\n",
       "      <td>50919992</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2023-01-01 01:41:36</td>\n",
       "      <td>NaT</td>\n",
       "      <td>nan</td>\n",
       "      <td>26350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>761304</td>\n",
       "      <td>0</td>\n",
       "      <td>50787738</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>2023-01-01 01:41:57</td>\n",
       "      <td>NaT</td>\n",
       "      <td>nan</td>\n",
       "      <td>27550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>754875f74fbd809411651574e4ddeb73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_scales  trnum_in  trnum_out  invnum_in  invnum_out  num_in  num_out  \\\n",
       "0          2    761304          0   73915704           0      41       41   \n",
       "1          3    761304          0   50919992           0      40       40   \n",
       "2          4    761304          0   50787738           0      39       39   \n",
       "\n",
       "              date_in date_out deltatetime  tare_in  tare_out  brutto  netto  \\\n",
       "0 2023-01-01 01:41:20      NaT         nan    27100         0       0      0   \n",
       "1 2023-01-01 01:41:36      NaT         nan    26350         0       0      0   \n",
       "2 2023-01-01 01:41:57      NaT         nan    27550         0       0      0   \n",
       "\n",
       "   deltaweight                        hash_group  \n",
       "0            0  754875f74fbd809411651574e4ddeb73  \n",
       "1            0  754875f74fbd809411651574e4ddeb73  \n",
       "2            0  754875f74fbd809411651574e4ddeb73  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывести первые значения таблицы\n",
    "scales_join_hash.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be91d3f7-af4e-4f6f-82ff-ec655cbc9eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6596 entries, 0 to 6595\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   id_result     6596 non-null   int64         \n",
      " 1   id_scales     6596 non-null   int64         \n",
      " 2   id_marriag    6596 non-null   int64         \n",
      " 3   trnum_in      6596 non-null   int64         \n",
      " 4   trnum_out     6596 non-null   int64         \n",
      " 5   invnum_in     6596 non-null   int64         \n",
      " 6   invnum_out    6596 non-null   int64         \n",
      " 7   num_in        6596 non-null   int64         \n",
      " 8   num_out       6596 non-null   int64         \n",
      " 9   date_in       6596 non-null   datetime64[ns]\n",
      " 10  date_out      6079 non-null   datetime64[ns]\n",
      " 11  date_marriag  375 non-null    datetime64[ns]\n",
      " 12  deltatetime   6596 non-null   object        \n",
      " 13  tare_in       6596 non-null   int64         \n",
      " 14  tare_out      6596 non-null   int64         \n",
      " 15  brutto        6596 non-null   int64         \n",
      " 16  netto         6596 non-null   int64         \n",
      " 17  deltaweight   6596 non-null   int64         \n",
      " 18  nact          6596 non-null   int64         \n",
      " 19  reason        375 non-null    object        \n",
      " 20  hash_group    6596 non-null   object        \n",
      "dtypes: datetime64[ns](3), int64(15), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Сводная информация по таблице 'join_table'\n",
    "join_hash_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fee9c0ff-a6cd-4f5d-9523-8291554fb332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6596"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Общее количество записей таблицы 'join_table'\n",
    "len(join_hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5cea1df-32ed-4efb-a9f8-690c91f51bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_result</th>\n",
       "      <th>id_scales</th>\n",
       "      <th>id_marriag</th>\n",
       "      <th>trnum_in</th>\n",
       "      <th>trnum_out</th>\n",
       "      <th>invnum_in</th>\n",
       "      <th>invnum_out</th>\n",
       "      <th>num_in</th>\n",
       "      <th>num_out</th>\n",
       "      <th>date_in</th>\n",
       "      <th>...</th>\n",
       "      <th>date_marriag</th>\n",
       "      <th>deltatetime</th>\n",
       "      <th>tare_in</th>\n",
       "      <th>tare_out</th>\n",
       "      <th>brutto</th>\n",
       "      <th>netto</th>\n",
       "      <th>deltaweight</th>\n",
       "      <th>nact</th>\n",
       "      <th>reason</th>\n",
       "      <th>hash_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>683482</td>\n",
       "      <td>683563</td>\n",
       "      <td>73218588</td>\n",
       "      <td>73218588</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2022-01-01 04:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>13,2</td>\n",
       "      <td>26400</td>\n",
       "      <td>26400</td>\n",
       "      <td>86900</td>\n",
       "      <td>60500</td>\n",
       "      <td>60500</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>e014f131431942ef0ffe305e99d6749d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>683482</td>\n",
       "      <td>683563</td>\n",
       "      <td>51920114</td>\n",
       "      <td>51920114</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>2022-01-01 04:46:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>13,2</td>\n",
       "      <td>25950</td>\n",
       "      <td>25950</td>\n",
       "      <td>88000</td>\n",
       "      <td>62050</td>\n",
       "      <td>62050</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>e014f131431942ef0ffe305e99d6749d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_result  id_scales  id_marriag  trnum_in  trnum_out  invnum_in  \\\n",
       "0          2          2           0    683482     683563   73218588   \n",
       "1          3          3           0    683482     683563   51920114   \n",
       "\n",
       "   invnum_out  num_in  num_out             date_in  ... date_marriag  \\\n",
       "0    73218588      40       40 2022-01-01 04:46:00  ...          NaT   \n",
       "1    51920114      39       39 2022-01-01 04:46:00  ...          NaT   \n",
       "\n",
       "  deltatetime tare_in  tare_out  brutto  netto  deltaweight  nact  reason  \\\n",
       "0        13,2   26400     26400   86900  60500        60500     0    None   \n",
       "1        13,2   25950     25950   88000  62050        62050     0    None   \n",
       "\n",
       "                         hash_group  \n",
       "0  e014f131431942ef0ffe305e99d6749d  \n",
       "1  e014f131431942ef0ffe305e99d6749d  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Первые значения таблицы 'join_table'\n",
    "join_hash_table.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "921c81e0-d752-4890-afe5-18c03ad9d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить переменную с именем результирующего CSV файла\n",
    "file_name_join_hash_table = '06__result-table-branch2.csv'\n",
    "path_file_join_hash_table = Path(dir_path,'res', 'data', file_name_join_hash_table)\n",
    "\n",
    "# Записать в данные в файл\n",
    "join_hash_table.to_csv(str(path_file_join_hash_table), index=False, sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad576a108e8407fa612c462da2b922c446627f16b36f7d316a57b8c93f3eb233"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
